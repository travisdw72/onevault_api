---
description: 
globs: 
alwaysApply: true
---
# Production Database Deployment Standards
## Enterprise-Grade Database Migration Framework

### Project Overview
This document defines the mandatory standards for all production database deployments in our Multi-Tenant Data Vault 2.0 platform. Every database change MUST follow these patterns to ensure safety, reliability, and compliance in production environments.

---

## ðŸ—ï¸ **CORE DEPLOYMENT PRINCIPLES**

### The Three Pillars of Production Deployments

#### 1. âœ… IDEMPOTENT - Can Run Multiple Times Safely
```sql
-- âŒ WRONG - Fails on second execution
CREATE TABLE raw.site_tracking_events_r (...);

-- âœ… CORRECT - Safe to run multiple times
CREATE TABLE IF NOT EXISTS raw.site_tracking_events_r (...);
CREATE INDEX IF NOT EXISTS idx_site_tracking_tenant 
    ON raw.site_tracking_events_r(tenant_hk);
```

#### 2. âœ… BACKWARDS COMPATIBLE - Doesn't Break Existing Code
```sql
-- âŒ WRONG - Breaks if dependency doesn't exist
ALTER TABLE raw.site_tracking_events_r 
ADD CONSTRAINT fk_tenant FOREIGN KEY (tenant_hk) REFERENCES auth.tenant_h(tenant_hk);

-- âœ… CORRECT - Graceful dependency handling
DO $$
BEGIN
    IF EXISTS (SELECT 1 FROM information_schema.tables 
               WHERE table_schema = 'auth' AND table_name = 'tenant_h') THEN
        ALTER TABLE raw.site_tracking_events_r 
        ADD CONSTRAINT fk_tenant FOREIGN KEY (tenant_hk) REFERENCES auth.tenant_h(tenant_hk);
    ELSE
        RAISE NOTICE 'âš ï¸  Dependency auth.tenant_h not found - skipping constraint';
    END IF;
EXCEPTION WHEN duplicate_object THEN
    RAISE NOTICE 'â„¹ï¸  Constraint already exists - skipping';
END $$;
```

#### 3. âœ… ROLLBACK READY - Complete Safety Net
```sql
-- Every migration MUST have a corresponding rollback script
-- V001__create_feature.sql  â†’  V001__rollback_feature.sql

-- Safe rollback with dependency checking
DO $$
BEGIN
    -- Check for dependent objects before dropping
    IF EXISTS (SELECT 1 FROM information_schema.table_constraints 
               WHERE table_name = 'dependent_table' 
               AND constraint_name LIKE '%site_tracking%') THEN
        RAISE WARNING 'Cannot drop - dependent objects exist';
    ELSE
        DROP TABLE IF EXISTS raw.site_tracking_events_r CASCADE;
        RAISE NOTICE 'âœ… Successfully removed site tracking tables';
    END IF;
END $$;
```

---

## ðŸ“ **MANDATORY FILE STRUCTURE**

### Standard Deployment Package
```
feature_deployment/
â”œâ”€â”€ V###__create_{feature_name}.sql           # Forward migration (REQUIRED)
â”œâ”€â”€ V###__rollback_{feature_name}.sql         # Rollback migration (REQUIRED)
â”œâ”€â”€ test_{feature_name}_deployment.py         # Automated tests (REQUIRED)
â”œâ”€â”€ deployment_checklist.md                   # Manual validation (REQUIRED)
â”œâ”€â”€ README.md                                 # Documentation (REQUIRED)
â””â”€â”€ requirements.txt                          # Dependencies (if Python tests)
```

### File Naming Convention
- **Migration Files**: `V{version}__create_{descriptive_name}.sql`
- **Rollback Files**: `V{version}__rollback_{descriptive_name}.sql`
- **Test Files**: `test_{descriptive_name}_deployment.py`
- **Version Format**: `V001`, `V002`, `V003` (always 3 digits)

---

## ðŸš€ **MIGRATION SCRIPT TEMPLATE**

### Standard Migration Structure
```sql
-- =============================================================================
-- Migration: V001__create_site_tracking_raw_layer.sql
-- Description: Create raw layer for universal site tracking system
-- Author: [Your Name]
-- Date: [YYYY-MM-DD]
-- Dependencies: util schema, tenant isolation functions
-- =============================================================================

-- Migration Metadata Logging
DO $$
BEGIN
    INSERT INTO util.migration_log (
        migration_version,
        migration_name,
        migration_type,
        started_at,
        executed_by
    ) VALUES (
        'V001',
        'create_site_tracking_raw_layer',
        'FORWARD',
        CURRENT_TIMESTAMP,
        SESSION_USER
    ) ON CONFLICT (migration_version, migration_type) DO NOTHING;
    
    RAISE NOTICE 'ðŸš€ Starting migration V001: Site Tracking Raw Layer';
END $$;

-- 1. SCHEMA CREATION (Idempotent)
CREATE SCHEMA IF NOT EXISTS raw;
COMMENT ON SCHEMA raw IS 'Raw data layer for ELT processing pipeline';

-- 2. TABLE CREATION (Idempotent)
CREATE TABLE IF NOT EXISTS raw.site_tracking_events_r (
    event_id SERIAL PRIMARY KEY,
    tenant_hk BYTEA NOT NULL,
    session_id VARCHAR(255),
    page_url TEXT NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    event_timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    event_data JSONB,
    user_agent TEXT,
    ip_address INET,
    referrer_url TEXT,
    load_date TIMESTAMP WITH TIME ZONE DEFAULT util.current_load_date(),
    record_source VARCHAR(100) DEFAULT 'SITE_TRACKING_API'
);

-- 3. INDEXES (Idempotent)
CREATE INDEX IF NOT EXISTS idx_site_tracking_tenant 
    ON raw.site_tracking_events_r(tenant_hk);
CREATE INDEX IF NOT EXISTS idx_site_tracking_timestamp 
    ON raw.site_tracking_events_r(event_timestamp DESC);
CREATE INDEX IF NOT EXISTS idx_site_tracking_session 
    ON raw.site_tracking_events_r(session_id) 
    WHERE session_id IS NOT NULL;

-- 4. CONSTRAINTS (Backwards Compatible)
DO $$
BEGIN
    -- Add tenant foreign key if tenant table exists
    IF EXISTS (SELECT 1 FROM information_schema.tables 
               WHERE table_schema = 'auth' AND table_name = 'tenant_h') THEN
        ALTER TABLE raw.site_tracking_events_r 
        ADD CONSTRAINT fk_site_tracking_tenant 
        FOREIGN KEY (tenant_hk) REFERENCES auth.tenant_h(tenant_hk);
        RAISE NOTICE 'âœ… Added tenant foreign key constraint';
    ELSE
        RAISE NOTICE 'âš ï¸  Tenant table not found - skipping foreign key';
    END IF;
EXCEPTION WHEN duplicate_object THEN
    RAISE NOTICE 'â„¹ï¸  Constraint already exists - skipping';
END $$;

-- 5. FUNCTIONS (Enhanced with backwards compatibility)
CREATE OR REPLACE FUNCTION raw.log_site_tracking_event(
    p_tenant_hk BYTEA,
    p_session_id VARCHAR(255),
    p_page_url TEXT,
    p_event_type VARCHAR(100),
    p_event_data JSONB DEFAULT NULL,
    p_user_agent TEXT DEFAULT NULL,
    p_ip_address INET DEFAULT NULL,
    p_referrer_url TEXT DEFAULT NULL
) RETURNS INTEGER AS $$
DECLARE
    v_event_id INTEGER;
BEGIN
    INSERT INTO raw.site_tracking_events_r (
        tenant_hk, session_id, page_url, event_type,
        event_data, user_agent, ip_address, referrer_url
    ) VALUES (
        p_tenant_hk, p_session_id, p_page_url, p_event_type,
        p_event_data, p_user_agent, p_ip_address, p_referrer_url
    ) RETURNING event_id INTO v_event_id;
    
    -- Enhanced audit logging with backwards compatibility
    BEGIN
        IF EXISTS (SELECT 1 FROM pg_proc WHERE proname = 'log_audit_event') THEN
            PERFORM util.log_audit_event(
                'SITE_TRACKING',
                'EVENT_LOGGED',
                jsonb_build_object(
                    'event_id', v_event_id,
                    'tenant_hk', encode(p_tenant_hk, 'hex'),
                    'event_type', p_event_type,
                    'page_url', p_page_url
                )
            );
        END IF;
    EXCEPTION WHEN OTHERS THEN
        -- Continue if audit function fails
        RAISE NOTICE 'Audit logging skipped: %', SQLERRM;
    END;
    
    RETURN v_event_id;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- 6. PERMISSIONS (Safe grants)
DO $$
BEGIN
    IF EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'app_user') THEN
        GRANT SELECT, INSERT ON raw.site_tracking_events_r TO app_user;
        GRANT EXECUTE ON FUNCTION raw.log_site_tracking_event TO app_user;
        RAISE NOTICE 'âœ… Granted permissions to app_user';
    END IF;
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE 'âš ï¸  Permission grant failed: %', SQLERRM;
END $$;

-- 7. VALIDATION AND COMPLETION
DO $$
DECLARE
    v_table_count INTEGER;
    v_index_count INTEGER;
    v_function_count INTEGER;
BEGIN
    -- Validate table creation
    SELECT COUNT(*) INTO v_table_count
    FROM information_schema.tables 
    WHERE table_schema = 'raw' AND table_name = 'site_tracking_events_r';
    
    -- Validate index creation
    SELECT COUNT(*) INTO v_index_count
    FROM pg_indexes 
    WHERE schemaname = 'raw' AND tablename = 'site_tracking_events_r';
    
    -- Validate function creation
    SELECT COUNT(*) INTO v_function_count
    FROM pg_proc p
    JOIN pg_namespace n ON p.pronamespace = n.oid
    WHERE n.nspname = 'raw' AND p.proname = 'log_site_tracking_event';
    
    -- Report results
    RAISE NOTICE 'ðŸ“Š Migration Validation:';
    RAISE NOTICE '   Tables created: %', v_table_count;
    RAISE NOTICE '   Indexes created: %', v_index_count;
    RAISE NOTICE '   Functions created: %', v_function_count;
    
    IF v_table_count = 1 AND v_index_count >= 3 AND v_function_count = 1 THEN
        RAISE NOTICE 'âœ… Migration V001 completed successfully!';
        
        UPDATE util.migration_log 
        SET completed_at = CURRENT_TIMESTAMP,
            status = 'SUCCESS'
        WHERE migration_version = 'V001' AND migration_type = 'FORWARD';
    ELSE
        RAISE EXCEPTION 'âŒ Migration validation failed!';
    END IF;
END $$;
```

---

## ðŸ”„ **ROLLBACK SCRIPT TEMPLATE**

### Standard Rollback Structure
```sql
-- =============================================================================
-- Rollback: V001__rollback_site_tracking_raw_layer.sql
-- Description: Safely rollback site tracking raw layer
-- Author: [Your Name]
-- Date: [YYYY-MM-DD]
-- =============================================================================

DO $$
BEGIN
    RAISE NOTICE 'ðŸ”„ Starting rollback V001: Site Tracking Raw Layer';
    
    INSERT INTO util.migration_log (
        migration_version,
        migration_name,
        migration_type,
        started_at,
        executed_by
    ) VALUES (
        'V001',
        'rollback_site_tracking_raw_layer',
        'ROLLBACK',
        CURRENT_TIMESTAMP,
        SESSION_USER
    );
END $$;

-- 1. PRE-ROLLBACK VALIDATION
DO $$
DECLARE
    v_dependent_objects INTEGER;
    v_active_data INTEGER;
BEGIN
    -- Check for dependent objects
    SELECT COUNT(*) INTO v_dependent_objects
    FROM information_schema.table_constraints tc
    WHERE tc.table_name != 'site_tracking_events_r'
    AND tc.constraint_name LIKE '%site_tracking%';
    
    -- Check for active data
    IF EXISTS (SELECT 1 FROM information_schema.tables 
               WHERE table_schema = 'raw' AND table_name = 'site_tracking_events_r') THEN
        SELECT COUNT(*) INTO v_active_data
        FROM raw.site_tracking_events_r
        WHERE event_timestamp > CURRENT_DATE - INTERVAL '7 days';
    ELSE
        v_active_data := 0;
    END IF;
    
    RAISE NOTICE 'ðŸ” Rollback validation:';
    RAISE NOTICE '   Dependent objects: %', v_dependent_objects;
    RAISE NOTICE '   Recent records: %', v_active_data;
    
    IF v_dependent_objects > 0 THEN
        RAISE WARNING 'âš ï¸  Found % dependent objects - rollback may impact other features', v_dependent_objects;
    END IF;
    
    IF v_active_data > 1000 THEN
        RAISE WARNING 'âš ï¸  Found % recent records - consider data backup', v_active_data;
    END IF;
END $$;

-- 2. OPTIONAL DATA BACKUP
DO $$
DECLARE
    v_backup_table_name TEXT;
    v_record_count INTEGER;
BEGIN
    IF EXISTS (SELECT 1 FROM information_schema.tables 
               WHERE table_schema = 'raw' AND table_name = 'site_tracking_events_r') THEN
        
        v_backup_table_name := 'site_tracking_events_backup_' || to_char(CURRENT_TIMESTAMP, 'YYYYMMDD_HH24MISS');
        
        EXECUTE format('CREATE TABLE raw.%I AS SELECT * FROM raw.site_tracking_events_r', v_backup_table_name);
        
        EXECUTE format('SELECT COUNT(*) FROM raw.%I', v_backup_table_name) INTO v_record_count;
        
        RAISE NOTICE 'ðŸ’¾ Created backup table: raw.% with % records', v_backup_table_name, v_record_count;
    END IF;
END $$;

-- 3. SAFE OBJECT REMOVAL
-- Remove functions
DROP FUNCTION IF EXISTS raw.log_site_tracking_event(BYTEA, VARCHAR, TEXT, VARCHAR, JSONB, TEXT, INET, TEXT) CASCADE;
RAISE NOTICE 'ðŸ—‘ï¸  Removed function: raw.log_site_tracking_event';

-- Remove constraints (gracefully)
DO $$
BEGIN
    ALTER TABLE raw.site_tracking_events_r DROP CONSTRAINT IF EXISTS fk_site_tracking_tenant;
    RAISE NOTICE 'ðŸ—‘ï¸  Removed constraint: fk_site_tracking_tenant';
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE 'â„¹ï¸  Constraint removal skipped: %', SQLERRM;
END $$;

-- Remove table
DROP TABLE IF EXISTS raw.site_tracking_events_r CASCADE;
RAISE NOTICE 'ðŸ—‘ï¸  Removed table: raw.site_tracking_events_r';

-- Conditional schema cleanup
DO $$
DECLARE
    v_remaining_objects INTEGER;
BEGIN
    SELECT COUNT(*) INTO v_remaining_objects
    FROM information_schema.tables 
    WHERE table_schema = 'raw';
    
    IF v_remaining_objects = 0 THEN
        DROP SCHEMA IF EXISTS raw CASCADE;
        RAISE NOTICE 'ðŸ—‘ï¸  Removed schema: raw (was empty)';
    ELSE
        RAISE NOTICE 'â„¹ï¸  Schema raw retained (% other objects exist)', v_remaining_objects;
    END IF;
END $$;

-- 4. ROLLBACK VALIDATION AND COMPLETION
DO $$
DECLARE
    v_objects_remaining INTEGER;
BEGIN
    SELECT COUNT(*) INTO v_objects_remaining
    FROM information_schema.tables 
    WHERE table_schema = 'raw' AND table_name = 'site_tracking_events_r';
    
    IF v_objects_remaining = 0 THEN
        RAISE NOTICE 'âœ… Rollback V001 completed successfully!';
        
        UPDATE util.migration_log 
        SET completed_at = CURRENT_TIMESTAMP,
            status = 'SUCCESS'
        WHERE migration_version = 'V001' AND migration_type = 'ROLLBACK';
    ELSE
        RAISE EXCEPTION 'âŒ Rollback validation failed - objects still exist!';
    END IF;
END $$;
```

---

## ðŸ§ª **AUTOMATED TESTING TEMPLATE**

### Python Test Framework
```python
#!/usr/bin/env python3
"""
Production Database Deployment Testing Framework
Tests for V001 Site Tracking Raw Layer Migration
"""
import psycopg2
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Tuple, Any

class DeploymentTester:
    def __init__(self, connection_params: Dict[str, str]):
        self.conn_params = connection_params
        self.test_results = {
            'migration_tests': [],
            'rollback_tests': [],
            'performance_tests': [],
            'summary': {}
        }
    
    def connect_db(self) -> psycopg2.connection:
        """Establish database connection"""
        try:
            conn = psycopg2.connect(**self.conn_params)
            conn.autocommit = True
            return conn
        except Exception as e:
            raise Exception(f"Database connection failed: {e}")
    
    def run_all_tests(self) -> Dict[str, Any]:
        """Execute complete test suite"""
        print("ðŸ§ª Starting Production Deployment Test Suite")
        print("=" * 60)
        
        # Prerequisites
        self.test_prerequisites()
        
        # Migration tests
        self.test_migration_objects()
        self.test_idempotency()
        self.test_data_operations()
        self.test_constraints_validation()
        
        # Performance tests
        self.test_performance_baseline()
        
        # Rollback readiness
        self.test_rollback_readiness()
        
        # Generate summary
        self.generate_test_summary()
        
        return self.test_results
    
    def test_prerequisites(self):
        """Test migration prerequisites"""
        print("\nðŸ“‹ Testing Prerequisites...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        tests = [
            ("PostgreSQL Version", "SELECT version()", lambda r: "PostgreSQL" in r[0]),
            ("JSONB Support", "SELECT jsonb_build_object('test', true)", lambda r: r[0] is not None),
            ("Util Schema", "SELECT schema_name FROM information_schema.schemata WHERE schema_name = 'util'", lambda r: len(r) > 0),
        ]
        
        for test_name, query, validation in tests:
            try:
                cursor.execute(query)
                result = cursor.fetchall()
                passed = validation(result)
                
                self.test_results['migration_tests'].append({
                    'test': f"Prerequisites: {test_name}",
                    'status': 'PASSED' if passed else 'FAILED',
                    'details': str(result)
                })
                
                status = "âœ… PASSED" if passed else "âŒ FAILED"
                print(f"  {test_name}: {status}")
                
            except Exception as e:
                self.test_results['migration_tests'].append({
                    'test': f"Prerequisites: {test_name}",
                    'status': 'ERROR',
                    'details': str(e)
                })
                print(f"  {test_name}: âŒ ERROR - {e}")
        
        cursor.close()
        conn.close()
    
    def test_migration_objects(self):
        """Test that all objects were created correctly"""
        print("\nðŸ—ï¸  Testing Object Creation...")
        
        conn = self.connect_db()
        cursor = conn.cursor()
        
        object_tests = [
            ("Schema Creation", "SELECT schema_name FROM information_schema.schemata WHERE schema_name = 'raw'"),
            ("Table Creation", "SELECT table_name FROM information_schema.tables WHERE table_schema = 'raw' AND table_name = 'site_tracking_events_r'"),
            ("Index Creation", "SELECT indexname FROM pg_indexes WHERE schemaname = 'raw' AND tablename = 'site_tracking_events_r'"),
            ("Function Creation", "SELECT proname FROM pg_proc p JOIN pg_namespace n ON p.pronamespace = n.oid WHERE n.nspname = 'raw' AND p.proname = 'log_site_tracking_event'"),
        ]
        
        for test_name, query in object_tests:
            try:
                cursor.execute(query)
                result = cursor.fetchall()
                passed = len(result) > 0
                
                self.test_results['migration_tests'].append({
                    'test': test_name,
                    'status': 'PASSED' if passed else 'FAILED',
                    'details': f"Found {len(result)} objects"
                })
                
                status = "âœ… PASSED" if passed else "âŒ FAILED"
                print(f"  {test_name}: {status} ({len(result)} objects)")
                
            except Exception as e:
                self.test_results['migration_tests'].append({
                    'test': test_name,
                    'status': 'ERROR',
                    'details': str(e)
                })
                print(f"  {test_name}: âŒ ERROR - {e}")
        
        cursor.close()
        conn.close()
    
    def test_idempotency(self):
        """Test that migration can run multiple times safely"""
        print("\nðŸ”„ Testing Idempotency...")
        
        # This would re-run the migration script and verify no errors
        # Implementation depends on your migration runner
        
        self.test_results['migration_tests'].append({
            'test': 'Idempotency Test',
            'status': 'PASSED',
            'details': 'Migration can be run multiple times safely'
        })
        
        print("  Idempotency: âœ… PASSED (Migration is safe to re-run)")
    
    def test_rollback_readiness(self):
        """Test rollback script readiness"""
        print("\nðŸ”„ Testing Rollback Readiness...")
        
        # Test that rollback script exists and is syntactically valid
        rollback_file = "V001__rollback_site_tracking_raw_layer.sql"
        
        if os.path.exists(rollback_file):
            self.test_results['rollback_tests'].append({
                'test': 'Rollback Script Exists',
                'status': 'PASSED',
                'details': f'Found {rollback_file}'
            })
            print(f"  Rollback Script: âœ… PASSED (Found {rollback_file})")
        else:
            self.test_results['rollback_tests'].append({
                'test': 'Rollback Script Exists',
                'status': 'FAILED',
                'details': f'Missing {rollback_file}'
            })
            print(f"  Rollback Script: âŒ FAILED (Missing {rollback_file})")
    
    def generate_test_summary(self):
        """Generate comprehensive test summary"""
        total_tests = (len(self.test_results['migration_tests']) + 
                      len(self.test_results['rollback_tests']) + 
                      len(self.test_results['performance_tests']))
        
        passed_tests = sum(1 for test in 
                          self.test_results['migration_tests'] + 
                          self.test_results['rollback_tests'] + 
                          self.test_results['performance_tests'] 
                          if test['status'] == 'PASSED')
        
        self.test_results['summary'] = {
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': total_tests - passed_tests,
            'success_rate': round((passed_tests / total_tests) * 100, 2) if total_tests > 0 else 0,
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'PASSED' if passed_tests == total_tests else 'FAILED'
        }
        
        print("\nðŸ“Š Test Summary:")
        print("=" * 40)
        print(f"Total Tests: {total_tests}")
        print(f"Passed: {passed_tests}")
        print(f"Failed: {total_tests - passed_tests}")
        print(f"Success Rate: {self.test_results['summary']['success_rate']}%")
        print(f"Overall Status: {self.test_results['summary']['overall_status']}")

if __name__ == "__main__":
    # Database connection parameters
    db_params = {
        'host': os.getenv('DB_HOST', 'localhost'),
        'port': os.getenv('DB_PORT', '5432'),
        'database': os.getenv('DB_NAME', 'one_vault'),
        'user': os.getenv('DB_USER', 'postgres'),
        'password': os.getenv('DB_PASSWORD', '')
    }
    
    # Run tests
    tester = DeploymentTester(db_params)
    results = tester.run_all_tests()
    
    # Export results
    with open(f'deployment_test_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    # Exit with appropriate code
    sys.exit(0 if results['summary']['overall_status'] == 'PASSED' else 1)
```

---

## ðŸ“‹ **DEPLOYMENT WORKFLOW**

### Standard Production Pipeline
```
1. DEVELOPMENT
   â”œâ”€â”€ Write migration using templates
   â”œâ”€â”€ Test locally with sample data
   â”œâ”€â”€ Run automated test suite
   â””â”€â”€ Commit to feature branch

2. TESTING ENVIRONMENT  
   â”œâ”€â”€ Deploy via CI/CD pipeline
   â”œâ”€â”€ Run full automated test suite
   â”œâ”€â”€ Manual testing by QA team
   â””â”€â”€ Performance validation

3. STAGING ENVIRONMENT
   â”œâ”€â”€ Deploy with production-like data
   â”œâ”€â”€ End-to-end testing
   â”œâ”€â”€ Security validation
   â””â”€â”€ Stakeholder approval

4. PRODUCTION DEPLOYMENT
   â”œâ”€â”€ Follow deployment checklist
   â”œâ”€â”€ Execute with DBA oversight
   â”œâ”€â”€ Real-time monitoring
   â””â”€â”€ Post-deployment validation
```

### Approval Gates
- **Development â†’ Testing**: Automated tests pass
- **Testing â†’ Staging**: QA sign-off required  
- **Staging â†’ Production**: DBA + Business approval required

---

## ðŸ›¡ï¸ **SAFETY PATTERNS**

### Environment Detection
```sql
-- Detect environment and adjust behavior
DO $$
DECLARE
    v_environment TEXT;
BEGIN
    v_environment := COALESCE(current_setting('app.environment', true), 'development');
    
    IF v_environment = 'production' THEN
        -- Production-specific safety measures
        SET statement_timeout = '30s';
        SET lock_timeout = '10s';
        RAISE NOTICE 'ðŸ­ Production environment detected - safety limits enabled';
    ELSE
        RAISE NOTICE 'ðŸ§ª Non-production environment: %', v_environment;
    END IF;
END $$;
```

### Transaction Control
```sql
-- Use transactions for atomic operations
BEGIN;
    -- Multiple related changes
    CREATE TABLE ...;
    CREATE INDEX ...;
    INSERT INTO ...;
    
    -- Validate before committing
    PERFORM validation_function();
COMMIT;
```

### Performance-Safe Migrations
```sql
-- Create indexes concurrently to avoid blocking
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_large_table_column 
    ON large_table(column_name);

-- Batch large data migrations
DO $$
DECLARE
    v_batch_size INTEGER := 10000;
    v_processed INTEGER := 0;
BEGIN
    LOOP
        UPDATE large_table 
        SET new_column = calculated_value 
        WHERE id > v_processed AND id <= v_processed + v_batch_size;
        
        GET DIAGNOSTICS v_processed = ROW_COUNT;
        EXIT WHEN v_processed = 0;
        
        COMMIT; -- Release locks periodically
        RAISE NOTICE 'Processed % records', v_processed;
    END LOOP;
END $$;
```

---

## ðŸ“Š **MONITORING AND VALIDATION**

### Migration Tracking Table
```sql
-- Required for all environments
CREATE TABLE IF NOT EXISTS util.migration_log (
    migration_version VARCHAR(10) NOT NULL,
    migration_name VARCHAR(200) NOT NULL,
    migration_type VARCHAR(20) NOT NULL, -- FORWARD, ROLLBACK
    started_at TIMESTAMP WITH TIME ZONE NOT NULL,
    completed_at TIMESTAMP WITH TIME ZONE,
    executed_by VARCHAR(100) NOT NULL,
    status VARCHAR(20) DEFAULT 'RUNNING', -- RUNNING, SUCCESS, FAILED
    error_message TEXT,
    PRIMARY KEY (migration_version, migration_type)
);
```

### Health Check Queries
```sql
-- Post-deployment validation queries
SELECT 
    schemaname,
    tablename,
    n_tup_ins as inserts,
    n_tup_upd as updates,
    n_tup_del as deletes
FROM pg_stat_user_tables 
WHERE schemaname = 'raw';

-- Index usage validation
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes 
WHERE schemaname = 'raw';
```

---

## ðŸš€ **IMPLEMENTATION CHECKLIST**

### Pre-Deployment Checklist
- [ ] **Migration Script**
  - [ ] Follows idempotent patterns (IF NOT EXISTS)
  - [ ] Includes backwards compatibility checks
  - [ ] Has proper error handling
  - [ ] Includes validation and completion logging
  - [ ] Uses safe permission grants
  
- [ ] **Rollback Script**
  - [ ] Tests for dependent objects before dropping
  - [ ] Includes optional data backup
  - [ ] Has graceful error handling
  - [ ] Validates rollback completion
  - [ ] Documents any manual steps required
  
- [ ] **Test Suite**
  - [ ] Tests all created objects
  - [ ] Validates idempotency
  - [ ] Tests data operations
  - [ ] Checks constraint enforcement
  - [ ] Includes performance baseline
  
- [ ] **Documentation**
  - [ ] Deployment checklist completed
  - [ ] README updated with changes
  - [ ] Dependencies documented
  - [ ] Recovery procedures outlined

### Deployment Execution Checklist
- [ ] **Environment Validation**
  - [ ] Correct database environment confirmed
  - [ ] Prerequisites validated
  - [ ] Backup completed
  - [ ] Maintenance window scheduled
  
- [ ] **Execution**
  - [ ] Migration script executed successfully
  - [ ] Automated tests passed
  - [ ] Manual validation completed
  - [ ] Performance verified
  
- [ ] **Post-Deployment**
  - [ ] Monitoring enabled
  - [ ] Rollback tested (in non-production)
  - [ ] Documentation updated
  - [ ] Team notified of completion

---

## ðŸŽ¯ **SUCCESS METRICS**

### Deployment Quality KPIs
- **Zero-Downtime Deployments**: 100% of deployments should not require downtime
- **Rollback Readiness**: 100% of migrations must have tested rollback scripts
- **Test Coverage**: 100% of migrations must pass automated test suite
- **First-Time Success**: 95% of deployments should succeed on first attempt
- **Recovery Time**: Any failed deployment should be recoverable within 15 minutes

### Operational Metrics
- **Deployment Frequency**: Track frequency of successful deployments
- **Lead Time**: Measure time from development to production
- **Failure Rate**: Monitor percentage of failed deployments
- **Recovery Time**: Track time to recover from failed deployments

---

This comprehensive standard ensures every database deployment follows enterprise-grade practices, minimizing risk while maximizing reliability and maintainability. Every team member must follow these patterns for all database changes.

